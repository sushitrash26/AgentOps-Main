{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Persistence and Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# here we are using in-memory database\n",
    "# but we can use other external databases like postgres or even redis for caching\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        # here we are adding our checkpointer\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# keep track of different threads inside checkpointer memory\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4ZqpjCM96QYQ9bvdh5TPY4sv', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 1158, 'total_tokens': 1181, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4d652bb1-da14-4cd4-93d3-a18d83b78eba-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_4ZqpjCM96QYQ9bvdh5TPY4sv'}])]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_4ZqpjCM96QYQ9bvdh5TPY4sv'}\n",
      "Back to the model!\n",
      "----> [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1742127310, \\'localtime\\': \\'2025-03-16 05:15\\'}, \\'current\\': {\\'last_updated_epoch\\': 1742127300, \\'last_updated\\': \\'2025-03-16 05:15\\', \\'temp_c\\': 8.9, \\'temp_f\\': 48.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 8.7, \\'wind_kph\\': 14.0, \\'wind_degree\\': 139, \\'wind_dir\\': \\'SE\\', \\'pressure_mb\\': 1020.0, \\'pressure_in\\': 30.13, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 89, \\'cloud\\': 50, \\'feelslike_c\\': 6.7, \\'feelslike_f\\': 44.0, \\'windchill_c\\': 6.1, \\'windchill_f\\': 43.0, \\'heatindex_c\\': 8.1, \\'heatindex_f\\': 46.6, \\'dewpoint_c\\': 7.4, \\'dewpoint_f\\': 45.4, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 15.1, \\'gust_kph\\': 24.3}}\"}, {\\'url\\': \\'https://world-weather.info/forecast/usa/san_francisco/march-2025/\\', \\'content\\': \"Weather in San Francisco in March 2025 (California) - Detailed Weather Forecast for a Month Weather in San Francisco Weather in San Francisco in March 2025 San Francisco Weather Forecast for March 2025 is based on long term prognosis and previous years\\' statistical data. 1 +54°+52° 2 +54°+50° 3 +54°+50° 4 +54°+48° 5 +61°+46° +59°+50° +59°+50° +61°+50° +61°+52° +61°+52° +63°+52° +63°+52° +61°+52° +61°+52° +63°+54° +61°+52° +63°+50° +61°+52° +61°+52° +59°+52° +61°+52° +59°+50° +57°+50° +57°+50° +59°+50° +59°+50° +61°+52° +63°+52° +63°+54° +63°+52° +63°+54° Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in Washington, D.C.+32° Sacramento+55° Pleasanton+52° Redwood City+55° San Leandro+55° San Mateo+54° San Rafael+55° San Ramon+52° South San Francisco+54° Vallejo+54° Palo Alto+55° Pacifica+55° Berkeley+57° Castro Valley+54° Concord+54° Daly City+54° Lagunitas+55° world\\'s temperature today day day Temperature units\"}]', name='tavily_search_results_json', tool_call_id='call_4ZqpjCM96QYQ9bvdh5TPY4sv')]\n",
      "----> [AIMessage(content='The current weather in San Francisco is partly cloudy, with a temperature of 8.9°C (48°F). The wind is coming from the southeast at 8.7 mph (14 kph), and the humidity is at 89%. The feels-like temperature is approximately 6.7°C (44°F), and there is no precipitation at the moment.', response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 1989, 'total_tokens': 2064, 'prompt_tokens_details': {'cached_tokens': 1024, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-2197563d-6fd3-4f44-9a2e-1b3dea33e4c7-0')]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(\"---->\", v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_SVRevStL6uDCPIvizpODvHCC', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 2075, 'total_tokens': 2098, 'prompt_tokens_details': {'cached_tokens': 2048, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4299f931-0dbf-42d1-b835-8f191b026b6a-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_SVRevStL6uDCPIvizpODvHCC'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_SVRevStL6uDCPIvizpODvHCC'}\n",
      "Back to the model!\n",
      "----> {'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.0522, \\'lon\\': -118.2428, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1742127613, \\'localtime\\': \\'2025-03-16 05:20\\'}, \\'current\\': {\\'last_updated_epoch\\': 1742127300, \\'last_updated\\': \\'2025-03-16 05:15\\', \\'temp_c\\': 10.3, \\'temp_f\\': 50.5, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 2.2, \\'wind_kph\\': 3.6, \\'wind_degree\\': 110, \\'wind_dir\\': \\'ESE\\', \\'pressure_mb\\': 1020.0, \\'pressure_in\\': 30.13, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 83, \\'cloud\\': 0, \\'feelslike_c\\': 10.6, \\'feelslike_f\\': 51.0, \\'windchill_c\\': 7.9, \\'windchill_f\\': 46.2, \\'heatindex_c\\': 8.3, \\'heatindex_f\\': 46.9, \\'dewpoint_c\\': 7.3, \\'dewpoint_f\\': 45.2, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 3.3, \\'gust_kph\\': 5.3}}\"}, {\\'url\\': \\'https://www.weather25.com/north-america/usa/california/los-angeles?page=month&month=March\\', \\'content\\': \\'Los Angeles weather in March 2025 | Weather25.com Los Angeles weather in March 2025 The wather in Los Angeles in March can vary between cold and nice weather days. Los Angeles in March Temperatures in Los Angeles in March Weather in Los Angeles in March - FAQ On average, there are 2 rainy days in Los Angeles during March. The weather in Los Angeles in March is good. On average, there are 0 snowy days in Los Angeles in March. More about the weather in Los Angeles Los Angeles 14 day weather Long range weather for Los Angeles Los Angeles weather in October Los Angeles weather in November Los Angeles Webcam Weather tomorrow Hotels in Los Angeles\\'}]', name='tavily_search_results_json', tool_call_id='call_SVRevStL6uDCPIvizpODvHCC')]}\n",
      "----> {'messages': [AIMessage(content='The current weather in Los Angeles is clear, with a temperature of 10.3°C (50.5°F). The wind is coming from the east-southeast at 2.2 mph (3.6 kph), and the humidity level is 83%. The feels-like temperature is approximately 10.6°C (51°F), and there is no precipitation at the moment.', response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 2684, 'total_tokens': 2765, 'prompt_tokens_details': {'cached_tokens': 2048, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-bb897f15-5cb4-435a-9649-093651693ee8-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(\"---->\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Los Angeles is currently warmer than San Francisco. The temperature in Los Angeles is 10.3°C (50.5°F), while in San Francisco, it is 8.9°C (48°F).', response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 2776, 'total_tokens': 2820, 'prompt_tokens_details': {'cached_tokens': 2688, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-09918845-b38b-4000-8330-3df234bc9ecc-0')]}\n"
     ]
    }
   ],
   "source": [
    "# we can call with same thread_id and so it has access to full history \n",
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=\"Could you please clarify what you're comparing to determine which is warmer? Are you comparing two specific locations, types of clothing, materials, or something else? Let me know so I can provide the appropriate information.\", response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 149, 'total_tokens': 192, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-c3daaf37-0f91-4a04-ba0b-cf49232c47c5-0')]}\n"
     ]
    }
   ],
   "source": [
    "# let change the thread_id\n",
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59a36-3941-459e-b9d1-ac5a4a1ed3ae",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# astream_events is an async method, so we need to use async checkpointer  \n",
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event Type: on_chain_start\n",
      "Event Type: on_chain_start\n",
      "Event Type: on_chain_end\n",
      "Event Type: on_chain_start\n",
      "Event Type: on_chat_model_start\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_end\n",
      "Event Type: on_chain_start\n",
      "Event Type: on_chain_end\n",
      "Event Type: on_chain_start\n",
      "Event Type: on_chain_end\n",
      "Event Type: on_chain_start\n",
      "Event Type: on_chain_end\n",
      "Event Type: on_chain_stream\n",
      "Event Type: on_chain_end\n",
      "Event Type: on_chain_stream\n",
      "Event Type: on_chain_start\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_ELSmZ2F8EZGoY7UfTT9TT3cV'}\n",
      "Event Type: on_tool_start\n",
      "Back to the model!\n",
      "Event Type: on_tool_end\n",
      "Event Type: on_chain_start\n",
      "Event Type: on_chain_end\n",
      "Event Type: on_chain_stream\n",
      "Event Type: on_chain_end\n",
      "Event Type: on_chain_stream\n",
      "Event Type: on_chain_start\n",
      "Event Type: on_chat_model_start\n",
      "Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_stream\n",
      "The|Event Type: on_chat_model_stream\n",
      " current|Event Type: on_chat_model_stream\n",
      " weather|Event Type: on_chat_model_stream\n",
      " in|Event Type: on_chat_model_stream\n",
      " San|Event Type: on_chat_model_stream\n",
      " Francisco|Event Type: on_chat_model_stream\n",
      " is|Event Type: on_chat_model_stream\n",
      " partly|Event Type: on_chat_model_stream\n",
      " cloudy|Event Type: on_chat_model_stream\n",
      " with|Event Type: on_chat_model_stream\n",
      " a|Event Type: on_chat_model_stream\n",
      " temperature|Event Type: on_chat_model_stream\n",
      " of|Event Type: on_chat_model_stream\n",
      " |Event Type: on_chat_model_stream\n",
      "48|Event Type: on_chat_model_stream\n",
      ".|Event Type: on_chat_model_stream\n",
      "0|Event Type: on_chat_model_stream\n",
      "°F|Event Type: on_chat_model_stream\n",
      " (|Event Type: on_chat_model_stream\n",
      "8|Event Type: on_chat_model_stream\n",
      ".|Event Type: on_chat_model_stream\n",
      "9|Event Type: on_chat_model_stream\n",
      "°C|Event Type: on_chat_model_stream\n",
      ").|Event Type: on_chat_model_stream\n",
      " The|Event Type: on_chat_model_stream\n",
      " wind|Event Type: on_chat_model_stream\n",
      " is|Event Type: on_chat_model_stream\n",
      " coming|Event Type: on_chat_model_stream\n",
      " from|Event Type: on_chat_model_stream\n",
      " the|Event Type: on_chat_model_stream\n",
      " southeast|Event Type: on_chat_model_stream\n",
      " at|Event Type: on_chat_model_stream\n",
      " |Event Type: on_chat_model_stream\n",
      "8|Event Type: on_chat_model_stream\n",
      ".|Event Type: on_chat_model_stream\n",
      "7|Event Type: on_chat_model_stream\n",
      " mph|Event Type: on_chat_model_stream\n",
      " (|Event Type: on_chat_model_stream\n",
      "14|Event Type: on_chat_model_stream\n",
      ".|Event Type: on_chat_model_stream\n",
      "0|Event Type: on_chat_model_stream\n",
      " k|Event Type: on_chat_model_stream\n",
      "ph|Event Type: on_chat_model_stream\n",
      "),|Event Type: on_chat_model_stream\n",
      " and|Event Type: on_chat_model_stream\n",
      " the|Event Type: on_chat_model_stream\n",
      " humidity|Event Type: on_chat_model_stream\n",
      " is|Event Type: on_chat_model_stream\n",
      " |Event Type: on_chat_model_stream\n",
      "89|Event Type: on_chat_model_stream\n",
      "%.|Event Type: on_chat_model_stream\n",
      " The|Event Type: on_chat_model_stream\n",
      " feels|Event Type: on_chat_model_stream\n",
      "-like|Event Type: on_chat_model_stream\n",
      " temperature|Event Type: on_chat_model_stream\n",
      " is|Event Type: on_chat_model_stream\n",
      " |Event Type: on_chat_model_stream\n",
      "44|Event Type: on_chat_model_stream\n",
      ".|Event Type: on_chat_model_stream\n",
      "0|Event Type: on_chat_model_stream\n",
      "°F|Event Type: on_chat_model_stream\n",
      " (|Event Type: on_chat_model_stream\n",
      "6|Event Type: on_chat_model_stream\n",
      ".|Event Type: on_chat_model_stream\n",
      "7|Event Type: on_chat_model_stream\n",
      "°C|Event Type: on_chat_model_stream\n",
      ").|Event Type: on_chat_model_stream\n",
      "Event Type: on_chat_model_end\n",
      "Event Type: on_chain_start\n",
      "Event Type: on_chain_end\n",
      "Event Type: on_chain_start\n",
      "Event Type: on_chain_end\n",
      "Event Type: on_chain_stream\n",
      "Event Type: on_chain_end\n",
      "Event Type: on_chain_stream\n",
      "Event Type: on_chain_end\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    print(\"Event Type:\", kind)\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8345dc12",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The| current| weather| in| San| Francisco| is| partly| cloudy| with| a| temperature| of| |48|.|0|°F| (|8|.|9|°C|).| The| wind| is| coming| from| the| southeast| at| |8|.|7| mph| (|14|.|0| k|ph|),| and| the| humidity| is| |89|%.| The| feels|-like| temperature| is| |44|.|0|°F| (|6|.|7|°C|).|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be88faf",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
